import json
import pandas as pd
from datetime import datetime
import requests
import os
from dotenv import load_dotenv
import time
import subprocess
import re  # æ­£è¦è¡¨ç¾ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import urllib.parse  # URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¿½åŠ 


def update_manga_data():
    """
    fetch_manga_data.pyã‚’å®Ÿè¡Œã—ã¦æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹
    """
    print("ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã¦ã„ã¾ã™...")
    try:
        # fetch_manga_data.pyã‚’å®Ÿè¡Œ
        result = subprocess.run(
            ["python", "fetch_manga_data.py"],
            capture_output=True,
            text=True,
            check=True,
        )
        print("ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†")
        print(result.stdout)
        return True
    except subprocess.CalledProcessError as e:
        print(f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼å‡ºåŠ›: {e.stderr}")
        return False


def rewrite_text_with_ai(original_text):
    """
    ã‚ªãƒ¼ãƒ—ãƒ³ãƒ«ãƒ¼ã‚¿ãƒ¼APIã‚’ä½¿ç”¨ã—ã¦æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒªãƒ©ã‚¤ãƒˆã™ã‚‹
    """
    load_dotenv()  # ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€

    # APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    api_key = os.getenv("OPENROUTER_API_KEY")

    if not api_key:
        raise ValueError(
            "ç’°å¢ƒå¤‰æ•°OPENROUTER_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚"
        )

    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãªã—ï¼‰
    model = os.getenv("OPENROUTER_MODEL")
    if not model:
        raise ValueError(
            "ç’°å¢ƒå¤‰æ•°OPENROUTER_MODELãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚"
        )

    print(f"ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«: {model}")

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
    system_prompt = os.getenv("OPENROUTER_SYSTEM_PROMPT")
    if not system_prompt:
        raise ValueError(
            "ç’°å¢ƒå¤‰æ•°OPENROUTER_SYSTEM_PROMPTãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚"
        )

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
    user_prompt_template = os.getenv("OPENROUTER_USER_PROMPT_TEMPLATE")
    if not user_prompt_template:
        raise ValueError(
            "ç’°å¢ƒå¤‰æ•°OPENROUTER_USER_PROMPT_TEMPLATEãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚"
        )

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ¿å…¥
    user_prompt = user_prompt_template.format(text=original_text)

    # ã‚ªãƒ¼ãƒ—ãƒ³ãƒ«ãƒ¼ã‚¿ãƒ¼APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    url = "https://openrouter.ai/api/v1/chat/completions"

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
    data = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": system_prompt,
            },
            {
                "role": "user",
                "content": user_prompt,
            },
        ],
    }

    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
        response = requests.post(url, headers=headers, json=data)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
        if response.status_code == 200:
            response_data = response.json()
            raw_text = response_data["choices"][0]["message"]["content"].strip()

            # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            print("AIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆå‡¦ç†å‰ï¼‰:")
            print(raw_text[:100] + "..." if len(raw_text) > 100 else raw_text)

            # AIã®å¿œç­”ã‹ã‚‰å®Ÿéš›ã®ãƒªãƒ©ã‚¤ãƒˆçµæœã‚’æŠ½å‡º
            rewritten_text = extract_rewritten_text(raw_text, original_text)

            # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            print("æŠ½å‡ºå¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ:")
            print(
                rewritten_text[:100] + "..."
                if len(rewritten_text) > 100
                else rewritten_text
            )

            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å›é¿ã™ã‚‹ãŸã‚ã®å¾…æ©Ÿ
            time.sleep(1)
            return rewritten_text
        else:
            error_msg = f"APIã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}"
            print(error_msg)
            # APIã‚¨ãƒ©ãƒ¼æ™‚ã¯å‡¦ç†ã‚’ä¸­æ­¢ã™ã‚‹
            raise ValueError(error_msg)

    except Exception as e:
        error_msg = f"ãƒªãƒ©ã‚¤ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}"
        print(error_msg)
        raise ValueError(error_msg)


def extract_rewritten_text(text, original_text=None):
    """
    AIã®å¿œç­”ã‹ã‚‰å®Ÿéš›ã®ãƒªãƒ©ã‚¤ãƒˆçµæœã ã‘ã‚’æŠ½å‡ºã™ã‚‹
    æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚„è‹±èªã®åˆ†æã‚’é™¤å»ã—ã€æ—¥æœ¬èªã®æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’è¿”ã™
    ç‰¹ã«ã€Œç¾¨ã¾ã—ã™ãã‚‹ã€ã€ŒèƒŒå¾³æ„Ÿã‚„ã°ã„ã€ãªã©ã®ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªè¡¨ç¾ã‚’å„ªå…ˆçš„ã«æŠ½å‡ºã™ã‚‹
    """
    import re
    import random

    # ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    print(f"å…ƒã®AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ:\n{text}")

    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å‰Šé™¤ (# ã‚„ ## ã§å§‹ã¾ã‚‹è¡Œ)
    text = re.sub(r"^#+ .*$", "", text, flags=re.MULTILINE)

    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®å¼·èª¿è¡¨ç¤ºã‚’å‰Šé™¤ (**text** ã‚„ *text*)
    text = re.sub(r"\*\*(.*?)\*\*", r"\1", text)
    text = re.sub(r"\*(.*?)\*", r"\1", text)

    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®ãƒªã‚¹ãƒˆï¼ˆæ•°å­—ã‚„è¨˜å·ã§å§‹ã¾ã‚‹è¡Œï¼‰ã‚’æ¤œå‡ºã—ã¦é™¤å»
    text = re.sub(r"^\d+\.\s.*$", "", text, flags=re.MULTILINE)  # æ•°å­—ãƒªã‚¹ãƒˆ
    text = re.sub(r"^[â€¢*\-]\s.*$", "", text, flags=re.MULTILINE)  # è¨˜å·ãƒªã‚¹ãƒˆ

    # ã‚³ãƒ¼ãƒ‰éƒ¨åˆ†ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
    text = re.sub(r"```.*?```", "", text, flags=re.DOTALL)

    # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å€™è£œã‚’ç”¨æ„
    hashtag_candidates = [
        "#å®˜èƒ½",
        "#ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼",
        "#èƒŒå¾³æ„Ÿ",
        "#ãƒ‰ã‚­ãƒ‰ã‚­",
        "#èˆˆå¥®",
        "#ãƒãƒ¼ãƒ¬ãƒ ",
        "#ã‚¢ãƒ€ãƒ«ãƒˆ",
        "#ã‚¨ãƒ­ãƒãƒ³ã‚¬",
        "#æˆäººå‘ã‘",
        "#ã‚¨ãƒ­æ¼«ç”»",
        "#ãŠã™ã™ã‚",
        "#äººæ°—",
        "#æ–°åˆŠ",
        "#BL",
        "#GL",
        "#TL",
        "#ãƒãƒ³ã‚¬",
        "#æ¼«ç”»",
        "#ã‚³ãƒŸãƒƒã‚¯",
        "#å¦„æƒ³",
        "#å¤§äººã®æ™‚é–“",
        "#ãƒ•ã‚§ãƒ",
        "#ã‚®ãƒ£ãƒ«",
        "#ç¾å°‘å¥³",
        "#ã‚¨ãƒƒãƒ",
        "#èª­æ›¸",
        "#é›»å­æ›¸ç±",
        "#æ¿¡ã‚Œã‚‹",
        "#ãŠã†ã¡æ™‚é–“",
        "#ç†±ã„",
    ]

    # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’é¸ã¶
    title_keywords = {
        "ãƒãƒ¼ãƒ¬ãƒ ": "#ãƒãƒ¼ãƒ¬ãƒ ",
        "å­•ã¾ã›": "#å¤§äººã®æ™‚é–“",
        "çµ¶é ‚": "#ã‚¨ãƒƒãƒ",
        "æ¾": "#ãƒ•ã‚§ãƒ",
        "é­”ç‰©": "#ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼",
        "è§¦æ‰‹": "#ãƒ•ã‚§ãƒ",
        "å¥³å­æ ¡ç”Ÿ": "#ç¾å°‘å¥³",
        "JK": "#ç¾å°‘å¥³",
        "å¦¹": "#èƒŒå¾³æ„Ÿ",
        "å§‰": "#èƒŒå¾³æ„Ÿ",
        "å…ˆç”Ÿ": "#èƒŒå¾³æ„Ÿ",
        "ç¾©ç†": "#èƒŒå¾³æ„Ÿ",
        "å­¦åœ’": "#é’æ˜¥",
        "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼": "#ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼",
        "ãƒ€ãƒ³ã‚¸ãƒ§ãƒ³": "#ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼",
        "ãƒ¡ã‚¤ãƒ‰": "#ç¾å°‘å¥³",
        "å·¨ä¹³": "#ãŠã£ã±ã„",
        "çˆ†ä¹³": "#ãŠã£ã±ã„",
        "BL": "#BL",
        "GL": "#GL",
        "TL": "#TL",
    }

    # åŸæ–‡ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡ºï¼ˆå¾Œã§ä½¿ç”¨ï¼‰
    title = ""
    if original_text:
        title_match = re.search(r"ã€(.+?)ã€", original_text)
        if title_match:
            title = title_match.group(1)

    # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’é¸å®š
    selected_hashtag = None
    if title:
        for keyword, tag in title_keywords.items():
            if keyword in title:
                selected_hashtag = tag
                break

    # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰é¸ã¹ãªã‹ã£ãŸå ´åˆã¯é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã¾ãŸã¯ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
    if not selected_hashtag:
        if "BL" in text:
            selected_hashtag = "#BL"
        elif "ç™¾åˆ" in text or "GL" in text:
            selected_hashtag = "#GL"
        elif "TL" in text:
            selected_hashtag = "#TL"
        else:
            selected_hashtag = random.choice(hashtag_candidates)

    # ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«è¡¨ç¾ã®æ¤œå‡ºï¼ˆå„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
    casual_expressions = []
    casual_patterns = [
        r"([^ã€‚\n]*?(ç¾¨ã¾ã—ã™ã|èƒŒå¾³æ„Ÿ|ãƒ¤ãƒã„|ãƒ¤ãƒã™ã|ãŸã¾ã‚“ãªã„|èˆˆå¥®ã™ã‚‹|æ­¢ã¾ã‚‰ãªã„|æœ€é«˜|æ¿€ã‚¢ãƒ„)[^ã€‚\n]*?)[ã€‚ï¼ï¼Ÿ\n]",
        r"([^ã€‚\n]*?(ä¿º|ç§|è‡ªåˆ†)[^ã€‚\n]*?(èˆˆå¥®|ãƒ‰ã‚­ãƒ‰ã‚­|ã‚¾ã‚¯ã‚¾ã‚¯|ãŸã¾ã‚‰ãªã„|å¥½ã|æœ€é«˜)[^ã€‚\n]*?)[ã€‚ï¼ï¼Ÿ\n]",
        r"([^ã€‚\n]*?[ğŸ˜ğŸ˜³ğŸ”¥ğŸ’¦â¤ï¸][^ã€‚\n]*?)[ã€‚ï¼ï¼Ÿ\n]",
    ]

    for pattern in casual_patterns:
        matches = re.findall(pattern, text)
        if matches:
            casual_expressions.extend([match[0] for match in matches])

    # 1. å¼·ã„æ„Ÿæƒ…è¡¨ç¾ã¨ä¸€äººç§°ã‚’å«ã‚€çŸ­ã‚ã®æ–‡ã‚’æ¢ã™
    short_expressions = []

    lines = text.split("\n")
    for line in lines:
        # æ˜ã‚‰ã‹ãªè§£èª¬ã‚„æŒ‡ç¤ºæ–‡ã¯é™¤å¤–
        if re.match(r"^(ä¾‹:|ä¾‹ï¼š|ã“ã‚“ãªæ„Ÿã˜|ä»¥ä¸‹ã®ã‚ˆã†ãª|ãƒ„ã‚¤ãƒ¼ãƒˆä¾‹|æŠ•ç¨¿ä¾‹)", line):
            continue

        # æ—¥æœ¬èªã‚’å«ã‚€è¡Œã‚’æŠ½å‡º
        if re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]", line):
            # æ–‡ç« ã‚’çŸ­ãã™ã‚‹ãŸã‚ã€ã€Œã€‚ã€ã€Œï¼ã€ã€Œï¼Ÿã€ã§åˆ†å‰²
            sentences = re.split(r"[ã€‚ï¼ï¼Ÿ]", line)
            for sentence in sentences:
                if not sentence.strip():
                    continue

                # é•·ã•ãŒ60æ–‡å­—ä»¥ä¸‹ã§ã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ ãŒã‚ã‚‹ã‚‚ã®ã‚’æŠ½å‡º
                if len(sentence) <= 60:
                    casual_score = 0
                    if re.search(r"(ä¿º|ç§|è‡ªåˆ†)", sentence):
                        casual_score += 5  # ä¸€äººç§°é‡è¦–
                    if re.search(
                        r"(ãƒ¤ãƒã„|ã™ã”ã„|æœ€é«˜|èˆˆå¥®|ç¾¨ã¾ã—ã„|èƒŒå¾³æ„Ÿ)", sentence
                    ):
                        casual_score += 4  # æ„Ÿæƒ…è¡¨ç¾é‡è¦–
                    if re.search(r"[â€¦ï¼ï¼Ÿ]", sentence):
                        casual_score += 2
                    if re.search(r"[ğŸ˜ğŸ˜³ğŸ”¥ğŸ’¦â¤ï¸]", sentence):
                        casual_score += 2

                    # ã‚¹ã‚³ã‚¢ãŒä¸€å®šä»¥ä¸Šãªã‚‰ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    if casual_score >= 2:
                        short_expressions.append((sentence.strip(), casual_score))

    # æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã®æº–å‚™
    final_text = ""

    # ä¸€äººç§°ã‚„æ„Ÿæƒ…è¡¨ç¾ã‚’å«ã‚€çŸ­ã‚ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å„ªå…ˆ
    if casual_expressions:
        # é•·ã•ãŒ60æ–‡å­—ä»¥ä¸‹ã®ã‚‚ã®ã‚’å„ªå…ˆ
        filtered_expressions = [
            (expr, len(expr)) for expr in casual_expressions if len(expr) <= 60
        ]
        if filtered_expressions:
            best_casual = min(filtered_expressions, key=lambda x: x[1])[
                0
            ]  # çŸ­ã„ã‚‚ã®ã‚’é¸æŠ
            final_text = best_casual
        else:
            # é•·ã™ãã‚‹å ´åˆã¯é©å½“ã«åˆ‡ã‚‹
            best_casual = casual_expressions[0]
            if len(best_casual) > 60:
                # æœ€åˆã®60æ–‡å­—ã‚’å–å¾—ã—ã€åˆ‡ã‚Œç›®ã‚’èª¿æ•´
                cut_text = best_casual[:60]
                # æœ€å¾Œã®æ–‡å­—ãŒé€”ä¸­ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã«èª¿æ•´
                if re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]$", cut_text):
                    # æœ€å¾Œã®æ–‡å­—ãŒæ—¥æœ¬èªãªã‚‰ã€ãã®æ–‡å­—ã‚’å«ã‚€å˜èªå…¨ä½“ã‚’æ¢ã™
                    for i in range(len(cut_text) - 1, 0, -1):
                        if not re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]", cut_text[i - 1]):
                            cut_text = cut_text[:i]
                            break
                final_text = cut_text + "â€¦"
            else:
                final_text = best_casual

    # çŸ­ã„è¡¨ç¾ãƒªã‚¹ãƒˆã‹ã‚‰ã‚‚æ¤œç´¢
    elif short_expressions:
        # ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
        short_expressions.sort(key=lambda x: x[1], reverse=True)
        final_text = short_expressions[0][0]  # æœ€ã‚‚ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªçŸ­æ–‡ã‚’é¸æŠ

    # ã„ãšã‚Œã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not final_text:
        fallback_texts = [
            "ã“ã‚Œãƒã‚¸ã§ãƒ¤ãƒã„å†…å®¹â€¦è¦‹ãŸç¬é–“èˆˆå¥®ãŒæ­¢ã¾ã‚‰ãªã„ğŸ˜³",
            "èƒŒå¾³æ„Ÿã™ã”ã„ã®ã«ç›®ãŒé›¢ã›ãªã„â€¦ã“ã‚“ãªã®åå‰‡ã ã‚ğŸ”¥",
            "è¦‹ã¦ã‚‹ã ã‘ã§ç¾¨ã¾ã—ã™ãã‚‹â€¦æœ€é«˜ã‹ã‚ˆğŸ˜",
            "ã“ã‚“ãªå±•é–‹å¾…ã£ã¦ãŸï¼è¶…èˆˆå¥®ã™ã‚‹å†…å®¹ã§ãƒ¤ãƒã„ğŸ˜³",
            "ç§ã®ç†æ€§ãŒå´©å£Šã—ãã†â€¦ã“ã‚“ãªæ¿ƒåšãªå±•é–‹ãƒ¤ãƒã™ãğŸ’¦",
            "ã“ã‚Œè¦‹ãŸç¬é–“ã«æˆ‘æ…¢ã§ããªããªã£ã¦å³è²·ã„ã—ãŸã‚wğŸ”¥",
            "æ€¥ã«ã“ã‚“ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã«ãªã‚‹ã¨ã‹åå‰‡ã™ãã‚‹â€¦ğŸ’¦",
        ]
        final_text = random.choice(fallback_texts)

    # æœ€çµ‚çš„ãªæ–‡ç« èª¿æ•´
    final_text = final_text.strip()

    # ä¸€äººç§°ãŒãªã‘ã‚Œã°è¿½åŠ ã‚’æ¤œè¨
    if not re.search(r"(ä¿º|ç§|è‡ªåˆ†)", final_text):
        first_person_prefixes = ["ç§ã“ã‚Œ", "ä¿ºã“ã‚Œ", "è‡ªåˆ†çš„ã«ã¯", "ç§çš„ã«", "ä¿ºçš„ã«"]
        if len(final_text) <= 50 and not final_text.startswith("ã“ã‚Œ"):
            final_text = random.choice(first_person_prefixes) + final_text

    # æœ«å°¾ã«æ„Ÿæƒ…è¡¨ç¾ãŒãªã‘ã‚Œã°è¿½åŠ 
    if not re.search(r"[ï¼ï¼Ÿâ€¦w]$", final_text):
        final_text += "â€¦ï¼"

    # çµµæ–‡å­—ãŒãªã‘ã‚Œã°è¿½åŠ 
    if not re.search(r"[ğŸ˜ğŸ˜³ğŸ”¥ğŸ’¦â¤ï¸]", final_text):
        emoji_options = ["ğŸ˜³", "ğŸ˜", "ğŸ”¥", "ğŸ’¦", "â¤ï¸"]
        final_text += random.choice(emoji_options)

    # PRã‚¿ã‚°ã¨ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’è¿½åŠ 
    final_text = final_text.strip() + "\n\n" + selected_hashtag + " #PR"

    # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ - ç©ºã®æŠ•ç¨¿ã‚„çµµæ–‡å­—ã ã‘ã®æŠ•ç¨¿ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
    text_content = re.sub(r"[ğŸ˜ğŸ˜³ğŸ”¥ğŸ’¦â¤ï¸\s]", "", final_text)
    if len(text_content) < 5:  # å®Ÿè³ªçš„ãªå†…å®¹ãŒå°‘ãªã™ãã‚‹å ´åˆ
        fallback = (
            "ã“ã‚Œãƒ¤ãƒã™ãã‚‹å†…å®¹â€¦èˆˆå¥®ãŒæ­¢ã¾ã‚‰ãªã„ğŸ˜³\n\n" + selected_hashtag + " #PR"
        )
        print(
            f"ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™: {fallback}"
        )
        return fallback

    print(f"æœ€çµ‚çš„ã«æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {final_text}")
    return final_text


def get_next_post_index():
    """
    æ¬¡ã«å‡¦ç†ã™ã¹ãæŠ•ç¨¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã™ã‚‹
    """
    # æœ€å¾Œã«å‡¦ç†ã—ãŸæŠ•ç¨¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    index_file = "last_processed_index.txt"

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
    if os.path.exists(index_file):
        try:
            with open(index_file, "r") as f:
                last_index = int(f.read().strip())
                return last_index + 1  # æ¬¡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™
        except:
            return 0  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯æœ€åˆã‹ã‚‰
    else:
        return 0  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯æœ€åˆã‹ã‚‰


def save_processed_index(index):
    """
    å‡¦ç†ã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã™ã‚‹
    """
    # æœ€å¾Œã«å‡¦ç†ã—ãŸæŠ•ç¨¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    index_file = "last_processed_index.txt"

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(index_file, "w") as f:
        f.write(str(index))


def process_manga_data(process_single=True):
    """
    å–å¾—ã—ãŸæ¼«ç”»ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢ãƒ»é¸å®š
    process_single: Trueã®å ´åˆã€æ¬¡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æŠ•ç¨¿1ä»¶ã ã‘ã‚’ãƒªãƒ©ã‚¤ãƒˆ
    """
    try:
        # ç”Ÿãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        with open("manga_data_raw.json", "r", encoding="utf-8") as f:
            manga_data = json.load(f)

        print(f"èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿: {len(manga_data)}ä»¶")

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
        df = pd.DataFrame(manga_data)

        print("ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆå®Œäº†")

        # å¿…è¦ãªãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
        df["is_fanza_exclusive"] = df["URL"].apply(
            lambda x: "exclusive" in x or "ç‹¬å " in str(x) if pd.notna(x) else False
        )

        # äºˆç´„å•†å“ã®é™¤å¤–ï¼ˆdateåˆ—ã®æ—¥ä»˜ãŒæœªæ¥ã®ã‚‚ã®ï¼‰
        today = datetime.now().strftime("%Y-%m-%d")

        def is_reservation(row):
            """äºˆç´„å•†å“ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°"""
            if "date" in row and pd.notna(row["date"]):
                try:
                    # æ—¥ä»˜æ–‡å­—åˆ—ã‹ã‚‰æ—¥ä»˜éƒ¨åˆ†ã®ã¿ã‚’å–ã‚Šå‡ºã™ï¼ˆæ™‚é–“éƒ¨åˆ†ã‚’é™¤å¤–ï¼‰
                    release_date = str(row["date"]).split(" ")[0]
                    # ç¾åœ¨ã®æ—¥ä»˜ã¨æ¯”è¼ƒ
                    return release_date > today
                except:
                    # æ—¥ä»˜è§£æã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯äºˆç´„å•†å“ã§ã¯ãªã„ã¨åˆ¤å®š
                    return False
            # dateåˆ—ãŒãªã„å ´åˆã‚‚äºˆç´„å•†å“ã§ã¯ãªã„ã¨åˆ¤å®š
            return False

        df["is_reservation"] = df.apply(is_reservation, axis=1)

        print("äºˆç´„å•†å“åˆ¤å®šå®Œäº†")

        # ä¾¡æ ¼ã‚’æ•°å€¤ã«å¤‰æ›ã™ã‚‹é–¢æ•°ï¼ˆ400å††æœªæº€ã®é™¤å¤–åˆ¤å®šã«ä½¿ç”¨ï¼‰
        def extract_price(row):
            if (
                "prices" in row
                and isinstance(row["prices"], dict)
                and "price" in row["prices"]
            ):
                try:
                    # ä¾¡æ ¼ã‹ã‚‰æ•°å­—ã ã‘ã‚’å–ã‚Šå‡ºã™
                    price_str = str(row["prices"]["price"])
                    price_num = int("".join(filter(str.isdigit, price_str)))
                    return price_num
                except:
                    return None
            return None

        # ä¾¡æ ¼ã‚’æ•°å€¤ã«å¤‰æ›
        df["price_value"] = df.apply(extract_price, axis=1)

        print("ä¾¡æ ¼æŠ½å‡ºå®Œäº†")

        # æ¡ä»¶ã«åˆè‡´ã™ã‚‹ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        df["is_new"] = df.get("is_new", False)
        df["is_exclusive"] = df["is_fanza_exclusive"]

        # ã‚¿ã‚¤ãƒˆãƒ«ã«ã€Œå˜è©±ã€ã‚’å«ã‚€ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
        df["is_tankowa"] = df["title"].apply(
            lambda x: "å˜è©±" in str(x) if pd.notna(x) else False
        )

        # ã‚¿ã‚¤ãƒˆãƒ«ã«ã€Œãƒãƒ™ãƒ«ã€ã‚’å«ã‚€ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
        df["is_novel"] = df["title"].apply(
            lambda x: "ãƒãƒ™ãƒ«" in str(x) if pd.notna(x) else False
        )

        print("å˜è©±ãƒ»ãƒãƒ™ãƒ«åˆ¤å®šå®Œäº†")

        # äºˆç´„å•†å“ã‚’é™¤å¤–
        df = df[~df["is_reservation"]]

        print(f"äºˆç´„å•†å“é™¤å¤–å¾Œ: {len(df)}ä»¶")

        # æ–°ç€ä½œå“ã‹ã‚‰ã€400å††æœªæº€ã¨å˜è©±ã¨ãƒãƒ™ãƒ«ã‚’é™¤å¤–
        selected_manga = df[
            (df["is_new"] == True)
            & ((df["price_value"].isnull()) | (df["price_value"] >= 400))
            & (~df["is_tankowa"])
            & (~df["is_novel"])
        ].copy()

        print(f"æ¡ä»¶é©åˆä½œå“çµã‚Šè¾¼ã¿å®Œäº†: {len(selected_manga)}ä»¶")

        # ä»¥ä¸‹ã€é¸å®šã•ã‚ŒãŸä½œå“ã®ã¿ã«é©ç”¨ã™ã‚‹å‡¦ç†ï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°æƒ…å ±ã®è¡¨ç¤ºã¯æ®‹ã™ï¼‰
        def format_ranking(row):
            if "ranking_info" not in row:
                return ""

            ranking_info = row["ranking_info"]
            ranking_text = []

            if "daily_rank" in ranking_info and ranking_info["daily_rank"] <= 50:
                ranking_text.append(f"æ—¥é–“{ranking_info['daily_rank']}ä½")

            if "weekly_rank" in ranking_info and ranking_info["weekly_rank"] <= 100:
                ranking_text.append(f"é€±é–“{ranking_info['weekly_rank']}ä½")

            if "monthly_rank" in ranking_info and ranking_info["monthly_rank"] <= 200:
                ranking_text.append(f"æœˆé–“{ranking_info['monthly_rank']}ä½")

            return "ãƒ»".join(ranking_text)

        selected_manga["ranking_text"] = selected_manga.apply(format_ranking, axis=1)

        # æŠ•ç¨¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
        def create_post_text(row):
            post_parts = []

            # ã‚¿ã‚¤ãƒˆãƒ«
            title = row.get("title", "")
            post_parts.append(f"ã€{title}ã€")

            # ä½œè€…
            if "author" in row:
                author = row["author"]
                if author:
                    post_parts.append(f"ä½œè€…: {author}")
            elif "artistName" in row:
                author = row["artistName"]
                if author:
                    post_parts.append(f"ä½œè€…: {author}")

            # ç‰¹å¾´ï¼ˆæ–°ç€ãƒ»é™å®šã®ã¿è¡¨ç¤ºï¼‰
            features = []
            if row["is_new"]:
                features.append("ğŸ†•æ–°ç€")
            if row["is_exclusive"]:
                features.append("ğŸ”’FANZAé™å®š")

            if features:
                post_parts.append("ã€" + "ãƒ»".join(features) + "ã€‘")

            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°æƒ…å ±ãŒã‚ã‚Œã°è¡¨ç¤º
            if row["ranking_text"]:
                post_parts.append(f"ğŸ“Šãƒ©ãƒ³ã‚­ãƒ³ã‚°: {row['ranking_text']}")

            # ä¾¡æ ¼
            if (
                "prices" in row
                and isinstance(row["prices"], dict)
                and "price" in row["prices"]
            ):
                price = row["prices"]["price"]
                post_parts.append(f"ğŸ’´ä¾¡æ ¼: {price}å††")

            # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’æœ¬æ–‡ã®å¾Œã«é…ç½®
            post_parts.append("#PR")

            # URLã¯post_textã«ã¯å«ã‚ãªã„ï¼ˆJSONã®åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã—ã¦ä¿å­˜ï¼‰
            # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURLã¯ãƒªãƒ©ã‚¤ãƒˆæ™‚ã«JSONã‹ã‚‰ç›´æ¥å–å¾—ã™ã‚‹

            return "\n".join(post_parts)

        # åˆæœŸã®æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
        selected_manga["post_text"] = selected_manga.apply(create_post_text, axis=1)

        # é¸å®šçµæœã‚’JSONã§ä¿å­˜
        result = []
        for _, row in selected_manga.iterrows():
            # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURLã‚’æ§‹ç¯‰ï¼ˆAPIçµŒç”±ã®å ´åˆã¯990ã‚’ä½¿ç”¨ï¼‰
            original_url = row.get("affiliateURL", "") or row.get("URL", "")

            # URLãŒã‚ã‚‹å ´åˆã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿®æ­£
            if original_url:
                # åŸºæœ¬URLéƒ¨åˆ†ã‚’æŠ½å‡º (ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ã®å‰ã¾ã§)
                base_url_parts = original_url.split("?")
                base_url = base_url_parts[0]

                # ã‚¯ã‚¨ãƒªéƒ¨åˆ†ãŒã‚ã‚Œã°è§£æ
                lurl = ""
                if len(base_url_parts) > 1:
                    query = base_url_parts[1]
                    query_parts = query.split("&")
                    for part in query_parts:
                        if part.startswith("lurl="):
                            lurl = part
                            break

                # æ–°ã—ã„URLã‚’æ§‹ç¯‰ï¼ˆAPIçµŒç”±ãªã®ã§990ã‚’ä½¿ç”¨ï¼‰
                if lurl:
                    fixed_url = f"{base_url}?{lurl}&af_id=kntbouzu777-990&ch=api"
                else:
                    # lurlãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®URLã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä»˜ã‘ã‚‹
                    fixed_url = f"{original_url}"
                    if "?" in fixed_url:
                        fixed_url = (
                            fixed_url.split("?")[0]
                            + "?lurl="
                            + urllib.parse.quote(fixed_url.split("?")[1])
                            + "&af_id=kntbouzu777-990&ch=api"
                        )
                    else:
                        fixed_url = fixed_url + "?af_id=kntbouzu777-990&ch=api"
            else:
                fixed_url = ""

            # ç”»åƒURLã¯å«ã‚ãªã„
            item = {
                "title": row.get("title", ""),
                "affiliateURL": fixed_url,
                "post_text": row.get("post_text", ""),
            }
            # authorãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¿½åŠ 
            if "author" in row:
                item["author"] = row["author"]
            result.append(item)

        with open("selected_manga.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        print(f"æŠ½å‡ºå®Œäº†: {len(result)}ä»¶ã®æ–°ç€ä½œå“ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")

        # 1ä»¶ã ã‘ãƒªãƒ©ã‚¤ãƒˆå‡¦ç†ã‚’ã™ã‚‹å ´åˆ
        if process_single and result:
            # æ¬¡ã«å‡¦ç†ã™ã¹ãã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            next_index = get_next_post_index()

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãƒªã‚¹ãƒˆã®ç¯„å›²å¤–ã®å ´åˆã¯æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™
            if next_index >= len(result):
                next_index = 0
                print(f"ã™ã¹ã¦ã®æŠ•ç¨¿ã‚’å‡¦ç†ã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’0ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚")

                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒ0ã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹å ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹
                print("ã™ã¹ã¦ã®æŠ•ç¨¿ã‚’å‡¦ç†ã—ãŸãŸã‚ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™")
                update_success = update_manga_data()

                if update_success:
                    print("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã«æˆåŠŸã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å†å®Ÿè¡Œã—ã¾ã™")
                    # è‡ªåˆ†è‡ªèº«ã‚’å†å¸°çš„ã«å‘¼ã³å‡ºã—ã¦ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§å‡¦ç†ã‚’è¡Œã†
                    return process_manga_data(process_single)
                else:
                    print("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã§å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")

            print(
                f"æŠ•ç¨¿ {next_index+1}/{len(result)} ã‚’å‡¦ç†ã—ã¾ã™: {result[next_index]['title']}"
            )

            # æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            post_text = result[next_index]["post_text"]

            # AIã§ãƒªãƒ©ã‚¤ãƒˆå‡¦ç†
            print("AIã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒªãƒ©ã‚¤ãƒˆå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
            rewritten_text = rewrite_text_with_ai(post_text)

            # ãƒªãƒ©ã‚¤ãƒˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã§çµæœã‚’æ›´æ–°
            result[next_index]["post_text"] = rewritten_text

            # å˜ä¸€ã®æŠ•ç¨¿çµæœã‚’JSONã§ä¿å­˜
            with open("current_post.json", "w", encoding="utf-8") as f:
                json.dump(result[next_index], f, ensure_ascii=False, indent=2)

            # å‡¦ç†ã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
            save_processed_index(next_index)

            print(f"æŠ•ç¨¿ {next_index+1} ã®ãƒªãƒ©ã‚¤ãƒˆå‡¦ç†å®Œäº†")
            print(f"ãƒªãƒ©ã‚¤ãƒˆçµæœã‚’ current_post.json ã«ä¿å­˜ã—ã¾ã—ãŸ")

        return True

    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        print(f"è©³ç´°: {traceback.format_exc()}")
        return False


if __name__ == "__main__":
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒã‚ã‚Œã°å‡¦ç†
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "--all":
        # å…¨ä»¶ãƒªãƒ©ã‚¤ãƒˆã™ã‚‹å ´åˆ
        process_manga_data(process_single=False)
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1ä»¶ã ã‘ãƒªãƒ©ã‚¤ãƒˆ
        process_manga_data(process_single=True)
